{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sho6210/MLR/blob/main/MLR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "C2uEt6ECeG3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.lib.function_base import vectorize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from numpy.core.fromnumeric import size\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tqdm\n",
        "import time\n",
        "import json\n",
        "import re\n",
        "import csv\n",
        "import urllib.request\n",
        "import shutil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2iu9jfOyXCG",
        "outputId": "0b0103dc-5861-48ba-ec0a-1bad3ecd58e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data load"
      ],
      "metadata": {
        "id": "WSBbUp9PiJnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# timer\n",
        "time_sta = time.time()\n",
        "\n",
        "# header\n",
        "HEADER = ['CVE-ID', 'Description', 'CVSS Base Score', 'AV', 'AC', 'PR', 'UI', 'S', 'C', 'I', 'A'] \n",
        "filelist = ['07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19']\n",
        "\n",
        "# Reading json files\n",
        "for i in filelist:\n",
        "  urllib.request.urlretrieve('https://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-20{}.json.zip'.format(i), \"nvdcve-1.1-20{}.json.zip\".format(i))\n",
        "  shutil.unpack_archive('/content/nvdcve-1.1-20{}.json.zip'.format(i), '/content')\n",
        "  filename_josn = '/content/nvdcve-1.1-20{}.json'.format(i)\n",
        "  json_open = open(filename_josn, 'r')\n",
        "  json_load = json.load(json_open)\n",
        "\n",
        "  # Output to cvs file\n",
        "  filename_csv = './data_set_20{0}.csv'.format(i)\n",
        "  with open(filename_csv, 'w', encoding='utf-8') as f:\n",
        "    # Header output\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(HEADER)\n",
        "\n",
        "    # Output of contents\n",
        "    for j in range(len(json_load[\"CVE_Items\"])):\n",
        "\n",
        "      # Initialisation of variables\n",
        "      out_description = \"\"\n",
        "      out_id = \"\"\n",
        "      \n",
        "      try:\n",
        "        for i in json_load[\"CVE_Items\"][j][\"cve\"][\"description\"]['description_data']:\n",
        "          out_description += i['value']\n",
        "        out_id = json_load[\"CVE_Items\"][j][\"cve\"][\"CVE_data_meta\"][\"ID\"]\n",
        "        out_cvss_score = json_load[\"CVE_Items\"][j][\"impact\"][\"baseMetricV3\"][\"cvssV3\"][\"baseScore\"]\n",
        "        out_cvss_vector = json_load[\"CVE_Items\"][j][\"impact\"][\"baseMetricV3\"][\"cvssV3\"][\"vectorString\"]\n",
        "        if out_cvss_vector != None:\n",
        "          out_cvss_vector_AV = re.search(r\"AV:.\", out_cvss_vector).group()\n",
        "          out_cvss_vector_AC = re.search(r\"AC:.\", out_cvss_vector).group()\n",
        "          out_cvss_vector_PR = re.search(r\"PR:.\", out_cvss_vector).group()\n",
        "          out_cvss_vector_UI = re.search(r\"UI:.\", out_cvss_vector).group()\n",
        "          out_cvss_vector_S = re.search(r\"/S:.\", out_cvss_vector).group()\n",
        "          out_cvss_vector_C = re.search(r\"/C:.\", out_cvss_vector).group()\n",
        "          out_cvss_vector_I = re.search(r\"/I:.\", out_cvss_vector).group()\n",
        "          out_cvss_vector_A = re.search(r\"/A:.\", out_cvss_vector).group()\n",
        "      \n",
        "      except KeyError:\n",
        "        continue    \n",
        "\n",
        "      # Output\n",
        "      row = [out_id, out_description, out_cvss_score, \n",
        "            out_cvss_vector_AV, out_cvss_vector_AC, out_cvss_vector_PR, \n",
        "            out_cvss_vector_UI, out_cvss_vector_S, out_cvss_vector_C, \n",
        "            out_cvss_vector_I, out_cvss_vector_A]\n",
        "      writer.writerow(row)\n"
      ],
      "metadata": {
        "id": "nmsK4EY-ZjTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data-Set"
      ],
      "metadata": {
        "id": "wxFMiYVheYRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_2007 = pd.read_csv(\"/content/data_set_2007.csv\", header=0)\n",
        "df_2008 = pd.read_csv(\"/content/data_set_2008.csv\", header=0)\n",
        "df_2009 = pd.read_csv(\"/content/data_set_2009.csv\", header=0)\n",
        "df_2010 = pd.read_csv(\"/content/data_set_2010.csv\", header=0)\n",
        "df_2011 = pd.read_csv(\"/content/data_set_2011.csv\", header=0)\n",
        "df_2012 = pd.read_csv(\"/content/data_set_2012.csv\", header=0)\n",
        "df_2013 = pd.read_csv(\"/content/data_set_2013.csv\", header=0)\n",
        "df_2014 = pd.read_csv(\"/content/data_set_2014.csv\", header=0)\n",
        "df_2015 = pd.read_csv(\"/content/data_set_2015.csv\", header=0)\n",
        "df_2016 = pd.read_csv(\"/content/data_set_2016.csv\", header=0)\n",
        "df_2017 = pd.read_csv(\"/content/data_set_2017.csv\", header=0)\n",
        "df_2018 = pd.read_csv(\"/content/data_set_2018.csv\", header=0)\n",
        "df_2019 = pd.read_csv(\"/content/data_set_2019.csv\", header=0)\n",
        "\n",
        "\n",
        "# df_0000 storage list\n",
        "list_df = [df_2007, df_2008, df_2009, df_2010, df_2011, df_2012, df_2013, df_2014, df_2015, df_2016, df_2017, df_2018, df_2019]"
      ],
      "metadata": {
        "id": "mi3BWBebeRLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading and data splitting"
      ],
      "metadata": {
        "id": "3rmQiwieyvmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def DataMake(split, metric, list_df):\n",
        "  # variable\n",
        "  label_train = []\n",
        "  label_test = []\n",
        "  sentences_train = []\n",
        "  sentences_test = []\n",
        "\n",
        "  # Split the correct answer labels and target sentences into study and test.\n",
        "  list_train = list_df[:split]\n",
        "  list_test = list_df[split:]\n",
        "  print('metric:', metric)\n",
        "  print('train:', len(list_train), 'test:', len(list_test))\n",
        "\n",
        "  # Store data frames for testing in df_test.\n",
        "  df_test = pd.concat(list_test)\n",
        "\n",
        "  # Extract and list metric value in a list.\n",
        "  for i in list_train:\n",
        "    label_train.append(i[metric].values)\n",
        "    sentences_train.append(i['Description'].values)\n",
        "  for i in list_test:\n",
        "    label_test.append(i[metric].values)\n",
        "    sentences_test.append(i['Description'].values)\n",
        "\n",
        "  # data for input\n",
        "  # metric value\n",
        "  y_train = np.concatenate(label_train, 0)\n",
        "  y_test = np.concatenate(label_test, 0)\n",
        "  # description\n",
        "  train_sentence = np.concatenate(sentences_train, 0)\n",
        "  test_sentence = np.concatenate(sentences_test, 0)\n",
        "\n",
        "  return y_train, y_test, train_sentence, test_sentence, df_test"
      ],
      "metadata": {
        "id": "7EFClJiGyi7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing (train)"
      ],
      "metadata": {
        "id": "YfYxevRwfneG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NLP_train(train_sentence):\n",
        "  # Natural Language Processing\n",
        "  # Creating BoW features with sklearn's CountVectorizer\n",
        "  vectorizer = CountVectorizer(stop_words=\"english\")\n",
        "  X_train = vectorizer.fit_transform(train_sentence)\n",
        "  \n",
        "  return X_train, vectorizer"
      ],
      "metadata": {
        "id": "UFh_yTKG_L3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial Logistic Regression (train)"
      ],
      "metadata": {
        "id": "OhGKDuML0g93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MLR_train(X_train, y_train):\n",
        "  # Create a classification model for MLR using vectorized features\n",
        "  lr = LogisticRegression(C=0.1, random_state=0, n_jobs=-1)\n",
        "  lr.fit(X_train, y_train)\n",
        "\n",
        "  return lr\n",
        "\n"
      ],
      "metadata": {
        "id": "A-Y15tpr_9jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing (test)"
      ],
      "metadata": {
        "id": "A1MAf62J0tPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NLP_test(test_sentence, vectorizer):\n",
        "  # Natural Language Processing\n",
        "  # Creating BoW features with sklearn's CountVectorizer.\n",
        "  X_test = vectorizer.transform(test_sentence)\n",
        "  \n",
        "  return X_test"
      ],
      "metadata": {
        "id": "JVv9EtnWlZrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial Logistic Regression (test)"
      ],
      "metadata": {
        "id": "2rxS6KVU0vh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MLR_test(metric, X_test, y_test, lr):\n",
        "  # Test data to confirm accuracy.\n",
        "  y_pred = lr.predict(X_test)\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "  # Branching when creating a table.\n",
        "  if metric == 'AV':\n",
        "    table = pd.DataFrame(cm, columns=['Predicted A', 'Predicted L', 'Predicted N', 'Predicted P'], index=['Actual A', 'Actual L', 'Actual N', 'Actual P'])\n",
        "  elif metric == 'AC':\n",
        "    table = pd.DataFrame(cm, columns=['Predicted H', 'Predicted L'], index=['Actual H', 'Actual L'])\n",
        "  elif metric == 'PR':\n",
        "    table = pd.DataFrame(cm, columns=['Predicted H', 'Predicted L', 'Predicted N'], index=['Actual H', 'Actual L', 'Actual N'])\n",
        "  elif metric == 'UI':\n",
        "    table = pd.DataFrame(cm, columns=['Predicted N', 'Predicted R'], index=['Actual N', 'Actual R'])\n",
        "  elif metric == 'S':\n",
        "    table = pd.DataFrame(cm, columns=['Predicted C', 'Predicted U'], index=['Actual C', 'Actual U'])\n",
        "  else:\n",
        "    table = pd.DataFrame(cm, columns=['Predicted H', 'Predicted L', 'Predicted N'], index=['Actual H', 'Actual L', 'Actual N'])\n",
        "\n",
        "  # Accuracy\n",
        "  print(\"accuracy:\", accuracy_score(y_test, y_pred))\n",
        "  print(table)\n",
        "  print('-'*70)\n",
        "\n",
        "  # Returns a list containing the prediction results and a data frame for testing.\n",
        "  return y_pred, df_test\n",
        "\n"
      ],
      "metadata": {
        "id": "65tQ7Pvnmg76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example"
      ],
      "metadata": {
        "id": "dYF-OpMa03Ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "metrics = ['AV', 'AC', 'PR', 'UI', 'S', 'C', 'I', 'A']\n",
        "split = 12\n",
        "\n",
        "for metric in metrics:\n",
        "  y_train, y_test, train_sentence, test_sentence, df_test = DataMake(split, metric, list_df)\n",
        "\n",
        "  X_train, vectorizer = NLP_train(train_sentence)\n",
        "  lr = MLR_train(X_train, y_train)\n",
        "\n",
        "  X_test = NLP_test(test_sentence, vectorizer)\n",
        "  MLR_test(metric, X_test, y_test, lr)\n",
        "\n",
        "# timer\n",
        "time_end = time.time()\n",
        "print('Processing time:', time_end - time_sta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB6I7HqcofQ2",
        "outputId": "7102521e-8dd1-4cfe-de04-0759b525e0e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metric: AV\n",
            "train: 12 test: 1\n",
            "accuracy: 0.8685452077812964\n",
            "          Predicted A  Predicted L  Predicted N  Predicted P\n",
            "Actual A          151           27          201            1\n",
            "Actual L            9         2299          902            8\n",
            "Actual N           47          714        10894            5\n",
            "Actual P            1           42           77           95\n",
            "----------------------------------------------------------------------\n",
            "metric: AC\n",
            "train: 12 test: 1\n",
            "accuracy: 0.9555354488463775\n",
            "          Predicted H  Predicted L\n",
            "Actual H          374          524\n",
            "Actual L          164        14411\n",
            "----------------------------------------------------------------------\n",
            "metric: PR\n",
            "train: 12 test: 1\n",
            "accuracy: 0.7880178375234279\n",
            "          Predicted H  Predicted L  Predicted N\n",
            "Actual H          372          378          392\n",
            "Actual L          118         2516         1692\n",
            "Actual N           61          639         9305\n",
            "----------------------------------------------------------------------\n",
            "metric: UI\n",
            "train: 12 test: 1\n",
            "accuracy: 0.8816648355199379\n",
            "          Predicted N  Predicted R\n",
            "Actual N         9676          638\n",
            "Actual R         1193         3966\n",
            "----------------------------------------------------------------------\n",
            "metric: S\n",
            "train: 12 test: 1\n",
            "accuracy: 0.9649712402249079\n",
            "          Predicted C  Predicted U\n",
            "Actual C         2000          419\n",
            "Actual U          123        12931\n",
            "----------------------------------------------------------------------\n",
            "metric: C\n",
            "train: 12 test: 1\n",
            "accuracy: 0.8371356556582434\n",
            "          Predicted H  Predicted L  Predicted N\n",
            "Actual H         8654          196          338\n",
            "Actual L          792         2078          127\n",
            "Actual N         1012           55         2221\n",
            "----------------------------------------------------------------------\n",
            "metric: I\n",
            "train: 12 test: 1\n",
            "accuracy: 0.8418535513475086\n",
            "          Predicted H  Predicted L  Predicted N\n",
            "Actual H         7091          142          596\n",
            "Actual L          491         2022          134\n",
            "Actual N         1058           26         3913\n",
            "----------------------------------------------------------------------\n",
            "metric: A\n",
            "train: 12 test: 1\n",
            "accuracy: 0.8712596135203258\n",
            "          Predicted H  Predicted L  Predicted N\n",
            "Actual H         8248           15          696\n",
            "Actual L          136           99           58\n",
            "Actual N         1084            3         5134\n",
            "----------------------------------------------------------------------\n",
            "Processing time: 122.90468454360962\n"
          ]
        }
      ]
    }
  ]
}